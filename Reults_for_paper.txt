ClaimBuster:

<class 'numpy.ndarray'> <class 'numpy.ndarray'>
15234 2043
Dataset Loaded: Shape =  (15234, 2033) (15234,)
(10663, 1) 182 (4571, 1)

Threshold = [0.4, 0.45, 0.499, 0.5, 0.55, 0.6, 0.7]
             precision    recall  f1-score   support

          0       0.98      0.88      0.93      4389
          1       0.14      0.47      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.80+/-0.05, Recall = 0.47+/-0.00

             precision    recall  f1-score   support

          0       0.97      0.92      0.95      4389
          1       0.17      0.37      0.23       182

avg / total       0.94      0.90      0.92      4571

Precision = 0.83+/-0.07, Recall = 0.37+/-0.00

             precision    recall  f1-score   support

          0       0.97      0.95      0.96      4389
          1       0.18      0.30      0.23       182

avg / total       0.94      0.92      0.93      4571

Precision = 0.87+/-0.06, Recall = 0.30+/-0.00

             precision    recall  f1-score   support

          0       0.97      0.95      0.96      4389
          1       0.18      0.27      0.22       182

avg / total       0.94      0.92      0.93      4571

Precision = 0.85+/-0.08, Recall = 0.27+/-0.00

             precision    recall  f1-score   support

          0       0.97      0.97      0.97      4389
          1       0.18      0.16      0.17       182

avg / total       0.93      0.94      0.94      4571

Precision = 0.85+/-0.09, Recall = 0.16+/-0.00

             precision    recall  f1-score   support

          0       0.96      0.98      0.97      4389
          1       0.20      0.12      0.15       182

avg / total       0.93      0.95      0.94      4571

Precision = 0.87+/-0.14, Recall = 0.12+/-0.00

             precision    recall  f1-score   support

          0       0.96      1.00      0.98      4389
          1       0.23      0.03      0.05       182

avg / total       0.93      0.96      0.94      4571

Precision = 0.89+/-0.20, Recall = 0.03+/-0.00



=============================================================
EMBEDDINGS
==============================================================


Dataset Loaded: Shape =  (15234, 2033) (15234,)
(10663, 300) 182 (4571, 300)
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
SVM_RBF
             precision    recall  f1-score   support

          0       0.97      0.92      0.95      4389
          1       0.15      0.33      0.20       182

avg / total       0.94      0.90      0.92      4571

Precision = 0.80+/-0.05, Recall = 0.33+/-0.00

10	0.1	0.013	0.069
20	0.25	0.054	0.19
30	0.233	0.053	0.192
50	0.22	0.052	0.196
80	0.237	0.055	0.215
100	0.21	0.049	0.198
500	0.28	0.042	0.25
1000	0.39	0.042	0.314
10	0.0	0.0	0.0
20	0.1	0.01	0.071
30	0.067	0.006	0.055
50	0.16	0.02	0.126
80	0.113	0.014	0.1
100	0.14	0.018	0.122
500	0.28	0.02	0.228
1000	0.385	0.02	0.289
SVM_Lin
             precision    recall  f1-score   support

          0       0.98      0.73      0.84      4389
          1       0.09      0.66      0.16       182

avg / total       0.95      0.73      0.81      4571

Precision = 0.72+/-0.07, Recall = 0.66+/-0.00

10	0.0	0.0	0.0
20	0.1	0.011	0.075
30	0.133	0.017	0.104
50	0.22	0.04	0.177
80	0.188	0.035	0.165
100	0.16	0.03	0.148
500	0.352	0.025	0.28
1000	0.566	0.025	0.407
10	0.1	0.01	0.064
20	0.1	0.012	0.077
30	0.167	0.023	0.128
50	0.2	0.035	0.165
80	0.188	0.035	0.166
100	0.16	0.03	0.149
500	0.352	0.025	0.28
1000	0.566	0.025	0.407
RF
             precision    recall  f1-score   support

          0       0.98      0.73      0.84      4389
          1       0.08      0.58      0.14       182

avg / total       0.94      0.72      0.81      4571

Precision = 0.68+/-0.05, Recall = 0.58+/-0.00

10	0.5	0.254	0.452
20	0.3	0.144	0.325
30	0.233	0.107	0.274
50	0.18	0.073	0.225
80	0.138	0.05	0.181
100	0.14	0.044	0.176
500	0.368	0.04	0.322
1000	0.533	0.04	0.418
10	0.5	0.254	0.452
20	0.3	0.144	0.325
30	0.233	0.107	0.274
50	0.18	0.073	0.225
80	0.138	0.05	0.181
100	0.14	0.044	0.176
500	0.368	0.04	0.322
1000	0.533	0.04	0.418
AB
             precision    recall  f1-score   support

          0       0.98      0.64      0.78      4389
          1       0.08      0.70      0.14       182

avg / total       0.95      0.64      0.75      4571

Precision = 0.67+/-0.04, Recall = 0.70+/-0.00

10	0.2	0.058	0.179
20	0.3	0.089	0.259
30	0.3	0.093	0.27
50	0.26	0.077	0.249
80	0.188	0.055	0.199
100	0.18	0.05	0.192
500	0.335	0.038	0.289
1000	0.505	0.038	0.391
10	0.2	0.045	0.158
20	0.35	0.106	0.283
30	0.4	0.134	0.332
50	0.28	0.095	0.266
80	0.188	0.063	0.201
100	0.18	0.056	0.194
500	0.28	0.038	0.255
1000	0.533	0.038	0.405
GradBoost
             precision    recall  f1-score   support

          0       0.98      0.72      0.83      4389
          1       0.09      0.66      0.16       182

avg / total       0.95      0.72      0.80      4571

Precision = 0.70+/-0.05, Recall = 0.66+/-0.00

10	0.1	0.025	0.095
20	0.15	0.032	0.137
30	0.167	0.034	0.153
50	0.24	0.054	0.212
80	0.263	0.064	0.237
100	0.26	0.065	0.24
500	0.396	0.046	0.33
1000	0.549	0.046	0.422
10	0.1	0.014	0.073
20	0.15	0.025	0.12
30	0.167	0.029	0.14
50	0.24	0.051	0.203
80	0.263	0.062	0.231
100	0.26	0.063	0.234
500	0.39	0.044	0.324
1000	0.549	0.044	0.418
Logistic
             precision    recall  f1-score   support

          0       0.98      0.73      0.84      4389
          1       0.10      0.69      0.17       182

avg / total       0.95      0.73      0.81      4571

Precision = 0.72+/-0.04, Recall = 0.69+/-0.00

10	0.1	0.011	0.066
20	0.15	0.021	0.112
30	0.2	0.033	0.155
50	0.22	0.043	0.183
80	0.212	0.045	0.189
100	0.19	0.04	0.176
500	0.379	0.034	0.306
1000	0.577	0.034	0.423
10	0.1	0.033	0.11
20	0.15	0.032	0.141
30	0.2	0.04	0.177
50	0.22	0.047	0.198
80	0.212	0.047	0.2
100	0.18	0.04	0.178
500	0.379	0.034	0.312
1000	0.582	0.034	0.432
E_RF
             precision    recall  f1-score   support

          0       0.98      0.83      0.90      4389
          1       0.12      0.59      0.20       182

avg / total       0.95      0.82      0.87      4571

Precision = 0.79+/-0.05, Recall = 0.59+/-0.00

10	0.2	0.058	0.173
20	0.2	0.053	0.184
30	0.267	0.07	0.235
50	0.22	0.055	0.209
80	0.25	0.061	0.233
100	0.27	0.067	0.25
500	0.467	0.057	0.387
1000	0.632	0.057	0.484
10	0.2	0.053	0.164
20	0.25	0.062	0.209
30	0.267	0.068	0.23
50	0.22	0.054	0.205
80	0.25	0.06	0.231
100	0.27	0.067	0.248
500	0.456	0.057	0.378
1000	0.632	0.057	0.482


=====================================================================
All features
======================================================================

15234 2043
Dataset Loaded: Shape =  (15234, 2033) (15234,)
(10663, 461) 182 (4571, 461)
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
Counter({0: 426, 1: 426})
SVM_RBF
             precision    recall  f1-score   support

          0       0.98      0.78      0.87      4389
          1       0.10      0.57      0.17       182

avg / total       0.94      0.77      0.84      4571

Precision = 0.70+/-0.03, Recall = 0.57+/-0.00

10	0.0	0.0	0.0
20	0.2	0.035	0.147
30	0.133	0.023	0.113
50	0.08	0.014	0.08
80	0.163	0.024	0.142
100	0.14	0.021	0.128
500	0.286	0.016	0.225
1000	0.549	0.016	0.381
10	0.0	0.0	0.0
20	0.2	0.034	0.145
30	0.133	0.022	0.112
50	0.1	0.015	0.093
80	0.15	0.022	0.133
100	0.14	0.021	0.128
500	0.28	0.016	0.222
1000	0.549	0.016	0.381
SVM_Lin
             precision    recall  f1-score   support

          0       0.98      0.74      0.85      4389
          1       0.10      0.65      0.17       182

avg / total       0.95      0.74      0.82      4571

Precision = 0.72+/-0.06, Recall = 0.65+/-0.00

10	0.2	0.079	0.212
20	0.1	0.039	0.137
30	0.133	0.036	0.153
50	0.18	0.039	0.181
80	0.15	0.03	0.158
100	0.13	0.025	0.142
500	0.396	0.025	0.32
1000	0.56	0.025	0.417
10	0.2	0.079	0.212
20	0.1	0.039	0.137
30	0.133	0.036	0.152
50	0.16	0.034	0.166
80	0.15	0.029	0.157
100	0.13	0.025	0.141
500	0.39	0.025	0.315
1000	0.571	0.025	0.423
RF
             precision    recall  f1-score   support

          0       0.98      0.74      0.84      4389
          1       0.09      0.59      0.15       182

avg / total       0.94      0.73      0.82      4571

Precision = 0.70+/-0.05, Recall = 0.59+/-0.00

10	0.2	0.056	0.176
20	0.2	0.058	0.192
30	0.167	0.046	0.172
50	0.2	0.048	0.195
80	0.225	0.053	0.216
100	0.2	0.047	0.199
500	0.324	0.042	0.281
1000	0.516	0.042	0.395
10	0.2	0.056	0.176
20	0.2	0.058	0.192
30	0.167	0.046	0.172
50	0.2	0.048	0.195
80	0.225	0.053	0.216
100	0.2	0.047	0.199
500	0.324	0.042	0.281
1000	0.516	0.042	0.395
AB
             precision    recall  f1-score   support

          0       0.98      0.65      0.78      4389
          1       0.07      0.65      0.13       182

avg / total       0.94      0.65      0.75      4571

Precision = 0.66+/-0.04, Recall = 0.65+/-0.00

10	0.2	0.122	0.286
20	0.25	0.098	0.29
30	0.2	0.073	0.245
50	0.18	0.057	0.219
80	0.138	0.04	0.176
100	0.16	0.039	0.187
500	0.242	0.03	0.23
1000	0.5	0.03	0.384
10	0.1	0.1	0.22
20	0.2	0.082	0.252
30	0.267	0.088	0.286
50	0.2	0.063	0.233
80	0.163	0.046	0.196
100	0.14	0.039	0.175
500	0.269	0.031	0.249
1000	0.5	0.031	0.386
GradBoost
             precision    recall  f1-score   support

          0       0.98      0.72      0.83      4389
          1       0.09      0.68      0.16       182

avg / total       0.95      0.72      0.80      4571

Precision = 0.70+/-0.05, Recall = 0.68+/-0.00

10	0.1	0.011	0.066
20	0.15	0.025	0.118
30	0.167	0.028	0.137
50	0.18	0.033	0.156
80	0.15	0.027	0.141
100	0.15	0.026	0.142
500	0.39	0.032	0.31
1000	0.577	0.032	0.42
10	0.1	0.01	0.064
20	0.15	0.023	0.115
30	0.167	0.028	0.135
50	0.16	0.027	0.139
80	0.163	0.027	0.147
100	0.15	0.025	0.14
500	0.385	0.031	0.306
1000	0.56	0.031	0.409
Logistic
             precision    recall  f1-score   support

          0       0.98      0.76      0.86      4389
          1       0.10      0.63      0.17       182

avg / total       0.95      0.76      0.83      4571

Precision = 0.73+/-0.06, Recall = 0.63+/-0.00

10	0.1	0.05	0.139
20	0.15	0.041	0.16
30	0.133	0.033	0.147
50	0.14	0.029	0.148
80	0.175	0.033	0.172
100	0.15	0.028	0.154
500	0.396	0.033	0.322
1000	0.615	0.033	0.452
10	0.2	0.056	0.176
20	0.15	0.038	0.149
30	0.167	0.037	0.161
50	0.14	0.027	0.142
80	0.15	0.026	0.148
100	0.14	0.024	0.141
500	0.396	0.031	0.318
1000	0.621	0.031	0.451
E_RF
             precision    recall  f1-score   support

          0       0.98      0.83      0.90      4389
          1       0.13      0.65      0.22       182

avg / total       0.95      0.82      0.87      4571

Precision = 0.79+/-0.05, Recall = 0.65+/-0.00

10	0.2	0.04	0.149
20	0.2	0.043	0.167
30	0.2	0.042	0.174
50	0.24	0.054	0.211
80	0.263	0.064	0.236
100	0.23	0.056	0.216
500	0.445	0.048	0.366
1000	0.67	0.048	0.5
10	0.2	0.045	0.158
20	0.15	0.034	0.14
30	0.2	0.043	0.178
50	0.24	0.055	0.214
80	0.263	0.065	0.239
100	0.23	0.057	0.219
500	0.434	0.05	0.36
1000	0.654	0.05	0.492
0 	 entype_PERSON
1 	 entype_LOCATION
2 	 entype_ORGANIZATION
3 	 entype_MISC
4 	 entype_MONEY
5 	 entype_NUMBER
6 	 entype_ORDINAL
7 	 entype_PERCENT
8 	 entype_DATE
9 	 entype_TIME
10 	 entype_DURATION
11 	 entype_SET
12 	 liwccat_feel
13 	 liwccat_percept
14 	 liwccat_certain
15 	 liwccat_time
16 	 topic_0
17 	 topic_1
18 	 topic_2
19 	 topic_3
20 	 topic_4
21 	 topic_5
22 	 topic_6
23 	 topic_7
24 	 topic_8
25 	 topic_9
26 	 topic_10
27 	 topic_11
28 	 topic_12
29 	 topic_13
30 	 topic_14
31 	 topic_15
32 	 topic_16
33 	 topic_17
34 	 topic_18
35 	 topic_19
36 	 sent_sim_tfidf
37 	 bi_go__to
38 	 bi_the__world
39 	 bi_you__know
40 	 bi_this__country
41 	 bi_be__go
42 	 bi_want__to
43 	 bi_i__think
44 	 bi_say__that
45 	 bi_senator__sanders
46 	 bi_president__obama
47 	 bi_the__united
48 	 bi_in__america
49 	 bi_wall__street
50 	 bi_the__highest
51 	 bi_secretary__clinton
52 	 bi_united__states
53 	 bi_one__of
54 	 bi_percent__of
55 	 bi_of__course
56 	 bi_i__say
57 	 bi_know__what
58 	 bi_people__in
59 	 bi_end__up
60 	 bi_a__lot
61 	 bi_vote__for
62 	 bi_look__at
63 	 bi_need__to
64 	 bi_think__it
65 	 bi_people__be
66 	 bi_we__need
67 	 bi_the__fact
68 	 bi_the__top
69 	 bi_million__of
70 	 bi_he__vote
71 	 bi_in__fact
72 	 bi_i__will
73 	 bi_to__make
74 	 bi_social__security
75 	 bi_people__who
76 	 bi_a__year
77 	 bi_tell__you
78 	 bi_can__not
79 	 bi_lot__of
80 	 bi_the__senate
81 	 bi_this__stage
82 	 bi_run__for
83 	 bi_talk__about
84 	 bi_of__dollar
85 	 bi_to__pay
86 	 bi_vote__against
87 	 bi_the__affordable
88 	 bi_be__pay
89 	 bi_care__act
90 	 bi_right__now
91 	 bi_affordable__care
92 	 bi_country__on
93 	 bi_i__support
94 	 bi_we__will
95 	 bi_the__last
96 	 bi_come__out
97 	 dep_compound
98 	 dep_case
99 	 dep_nummod
100 	 dep_amod
101 	 dep_det
102 	 dep_punct
103 	 embed_0
104 	 embed_1
105 	 embed_2
106 	 embed_3
107 	 embed_4
108 	 embed_5
109 	 embed_6
110 	 embed_7
111 	 embed_8
112 	 embed_9
113 	 embed_10
114 	 embed_11
115 	 embed_12
116 	 embed_13
117 	 embed_14
118 	 embed_15
119 	 embed_16
120 	 embed_17
121 	 embed_18
122 	 embed_19
123 	 embed_20
124 	 embed_21
125 	 embed_22
126 	 embed_23
127 	 embed_24
128 	 embed_25
129 	 embed_26
130 	 embed_27
131 	 embed_28
132 	 embed_29
133 	 embed_30
134 	 embed_31
135 	 embed_32
136 	 embed_33
137 	 embed_34
138 	 embed_35
139 	 embed_36
140 	 embed_37
141 	 embed_38
142 	 embed_39
143 	 embed_40
144 	 embed_41
145 	 embed_42
146 	 embed_43
147 	 embed_44
148 	 embed_45
149 	 embed_46
150 	 embed_47
151 	 embed_48
152 	 embed_49
153 	 embed_50
154 	 embed_51
155 	 embed_52
156 	 embed_53
157 	 embed_54
158 	 embed_55
159 	 embed_56
160 	 embed_57
161 	 embed_58
162 	 embed_59
163 	 embed_60
164 	 embed_61
165 	 embed_62
166 	 embed_63
167 	 embed_64
168 	 embed_65
169 	 embed_66
170 	 embed_67
171 	 embed_68
172 	 embed_69
173 	 embed_70
174 	 embed_71
175 	 embed_72
176 	 embed_73
177 	 embed_74
178 	 embed_75
179 	 embed_76
180 	 embed_77
181 	 embed_78
182 	 embed_79
183 	 embed_80
184 	 embed_81
185 	 embed_82
186 	 embed_83
187 	 embed_84
188 	 embed_85
189 	 embed_86
190 	 embed_87
191 	 embed_88
192 	 embed_89
193 	 embed_90
194 	 embed_91
195 	 embed_92
196 	 embed_93
197 	 embed_94
198 	 embed_95
199 	 embed_96
200 	 embed_97
201 	 embed_98
202 	 embed_99
203 	 embed_100
204 	 embed_101
205 	 embed_102
206 	 embed_103
207 	 embed_104
208 	 embed_105
209 	 embed_106
210 	 embed_107
211 	 embed_108
212 	 embed_109
213 	 embed_110
214 	 embed_111
215 	 embed_112
216 	 embed_113
217 	 embed_114
218 	 embed_115
219 	 embed_116
220 	 embed_117
221 	 embed_118
222 	 embed_119
223 	 embed_120
224 	 embed_121
225 	 embed_122
226 	 embed_123
227 	 embed_124
228 	 embed_125
229 	 embed_126
230 	 embed_127
231 	 embed_128
232 	 embed_129
233 	 embed_130
234 	 embed_131
235 	 embed_132
236 	 embed_133
237 	 embed_134
238 	 embed_135
239 	 embed_136
240 	 embed_137
241 	 embed_138
242 	 embed_139
243 	 embed_140
244 	 embed_141
245 	 embed_142
246 	 embed_143
247 	 embed_144
248 	 embed_145
249 	 embed_146
250 	 embed_147
251 	 embed_148
252 	 embed_149
253 	 embed_150
254 	 embed_151
255 	 embed_152
256 	 embed_153
257 	 embed_154
258 	 embed_155
259 	 embed_156
260 	 embed_157
261 	 embed_158
262 	 embed_159
263 	 embed_160
264 	 embed_161
265 	 embed_162
266 	 embed_163
267 	 embed_164
268 	 embed_165
269 	 embed_166
270 	 embed_167
271 	 embed_168
272 	 embed_169
273 	 embed_170
274 	 embed_171
275 	 embed_172
276 	 embed_173
277 	 embed_174
278 	 embed_175
279 	 embed_176
280 	 embed_177
281 	 embed_178
282 	 embed_179
283 	 embed_180
284 	 embed_181
285 	 embed_182
286 	 embed_183
287 	 embed_184
288 	 embed_185
289 	 embed_186
290 	 embed_187
291 	 embed_188
292 	 embed_189
293 	 embed_190
294 	 embed_191
295 	 embed_192
296 	 embed_193
297 	 embed_194
298 	 embed_195
299 	 embed_196
300 	 embed_197
301 	 embed_198
302 	 embed_199
303 	 embed_200
304 	 embed_201
305 	 embed_202
306 	 embed_203
307 	 embed_204
308 	 embed_205
309 	 embed_206
310 	 embed_207
311 	 embed_208
312 	 embed_209
313 	 embed_210
314 	 embed_211
315 	 embed_212
316 	 embed_213
317 	 embed_214
318 	 embed_215
319 	 embed_216
320 	 embed_217
321 	 embed_218
322 	 embed_219
323 	 embed_220
324 	 embed_221
325 	 embed_222
326 	 embed_223
327 	 embed_224
328 	 embed_225
329 	 embed_226
330 	 embed_227
331 	 embed_228
332 	 embed_229
333 	 embed_230
334 	 embed_231
335 	 embed_232
336 	 embed_233
337 	 embed_234
338 	 embed_235
339 	 embed_236
340 	 embed_237
341 	 embed_238
342 	 embed_239
343 	 embed_240
344 	 embed_241
345 	 embed_242
346 	 embed_243
347 	 embed_244
348 	 embed_245
349 	 embed_246
350 	 embed_247
351 	 embed_248
352 	 embed_249
353 	 embed_250
354 	 embed_251
355 	 embed_252
356 	 embed_253
357 	 embed_254
358 	 embed_255
359 	 embed_256
360 	 embed_257
361 	 embed_258
362 	 embed_259
363 	 embed_260
364 	 embed_261
365 	 embed_262
366 	 embed_263
367 	 embed_264
368 	 embed_265
369 	 embed_266
370 	 embed_267
371 	 embed_268
372 	 embed_269
373 	 embed_270
374 	 embed_271
375 	 embed_272
376 	 embed_273
377 	 embed_274
378 	 embed_275
379 	 embed_276
380 	 embed_277
381 	 embed_278
382 	 embed_279
383 	 embed_280
384 	 embed_281
385 	 embed_282
386 	 embed_283
387 	 embed_284
388 	 embed_285
389 	 embed_286
390 	 embed_287
391 	 embed_288
392 	 embed_289
393 	 embed_290
394 	 embed_291
395 	 embed_292
396 	 embed_293
397 	 embed_294
398 	 embed_295
399 	 embed_296
400 	 embed_297
401 	 embed_298
402 	 embed_299
403 	 pos_$
404 	 pos_quotes
405 	 pos_dquotes
406 	 pos_(
407 	 pos_)
408 	 pos_,
409 	 pos_--
410 	 pos_.
411 	 pos_:
412 	 pos_CC
413 	 pos_CD
414 	 pos_DT
415 	 pos_EX
416 	 pos_FW
417 	 pos_IN
418 	 pos_JJ
419 	 pos_JJR
420 	 pos_JJS
421 	 pos_LS
422 	 pos_MD
423 	 pos_NN
424 	 pos_NNP
425 	 pos_NNPS
426 	 pos_NNS
427 	 pos_PDT
428 	 pos_POS
429 	 pos_PRP
430 	 pos_PRP$
431 	 pos_RB
432 	 pos_RBR
433 	 pos_RBS
434 	 pos_RP
435 	 pos_SYM
436 	 pos_TO
437 	 pos_UH
438 	 pos_VB
439 	 pos_VBD
440 	 pos_VBG
441 	 pos_VBN
442 	 pos_VBP
443 	 pos_VBZ
444 	 pos_WDT
445 	 pos_WP
446 	 pos_WP$
447 	 pos_WRB
448 	 compound
449 	 neg
450 	 neu
451 	 pos
452 	 sub_weak
453 	 sub_strong
454 	 length
455 	 verbcat_report
456 	 verbcat_knowledge
457 	 verbcat_belief
458 	 verbcat_doubt
459 	 verbcat_perception
460 	 past



======================================================================
FINAL CLASSIFIER

15234 2043
Dataset Loaded: Shape =  (15234, 2033) (15234,)
(10663, 461) 182 (4571, 461)


             precision    recall  f1-score   support

          0       0.98      0.88      0.93      4389
          1       0.14      0.47      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.82+/-0.06, Recall = 0.47+/-0.00

10	0.2	0.05	0.164
20	0.2	0.053	0.182
30	0.2	0.05	0.186
50	0.2	0.047	0.191
80	0.188	0.041	0.184
100	0.2	0.043	0.193
500	0.374	0.038	0.312
1000	0.61	0.038	0.452
10	0.2	0.072	0.205
20	0.2	0.062	0.206
30	0.233	0.065	0.228
50	0.2	0.053	0.206
80	0.188	0.045	0.194
100	0.19	0.044	0.195
500	0.39	0.04	0.328
1000	0.604	0.04	0.455

             precision    recall  f1-score   support

          0       0.97      0.89      0.93      4389
          1       0.15      0.45      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.79+/-0.08, Recall = 0.45+/-0.00

10	0.1	0.017	0.078
20	0.2	0.037	0.157
30	0.2	0.039	0.167
50	0.18	0.036	0.162
80	0.175	0.034	0.164
100	0.2	0.038	0.183
500	0.379	0.034	0.306
1000	0.604	0.034	0.439
10	0.1	0.02	0.085
20	0.2	0.042	0.165
30	0.167	0.034	0.15
50	0.2	0.041	0.18
80	0.175	0.036	0.167
100	0.19	0.038	0.179
500	0.363	0.034	0.298
1000	0.604	0.034	0.442

             precision    recall  f1-score   support

          0       0.98      0.88      0.93      4389
          1       0.14      0.47      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.81+/-0.07, Recall = 0.47+/-0.00

10	0.2	0.05	0.164
20	0.2	0.047	0.176
30	0.167	0.038	0.158
50	0.2	0.045	0.187
80	0.175	0.037	0.172
100	0.18	0.037	0.176
500	0.385	0.033	0.315
1000	0.604	0.033	0.445
10	0.2	0.058	0.179
20	0.2	0.049	0.184
30	0.167	0.039	0.164
50	0.2	0.045	0.19
80	0.175	0.037	0.174
100	0.18	0.038	0.179
500	0.385	0.035	0.317
1000	0.604	0.035	0.447
Counter({0: 426, 1: 426})

             precision    recall  f1-score   support

          0       0.98      0.89      0.93      4389
          1       0.15      0.49      0.23       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.80+/-0.08, Recall = 0.49+/-0.00

10	0.1	0.025	0.095
20	0.15	0.026	0.127
30	0.2	0.037	0.167
50	0.2	0.039	0.177
80	0.175	0.034	0.165
100	0.19	0.037	0.177
500	0.401	0.036	0.322
1000	0.599	0.036	0.438
10	0.1	0.02	0.085
20	0.15	0.023	0.12
30	0.2	0.034	0.161
50	0.22	0.044	0.188
80	0.175	0.034	0.163
100	0.19	0.037	0.175
500	0.396	0.036	0.318
1000	0.599	0.036	0.437

             precision    recall  f1-score   support

          0       0.98      0.88      0.93      4389
          1       0.14      0.46      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.80+/-0.06, Recall = 0.46+/-0.00

10	0.2	0.045	0.155
20	0.2	0.044	0.169
30	0.233	0.053	0.199
50	0.2	0.045	0.184
80	0.175	0.037	0.17
100	0.18	0.037	0.174
500	0.39	0.036	0.319
1000	0.599	0.036	0.443
10	0.2	0.039	0.143
20	0.2	0.038	0.157
30	0.233	0.049	0.191
50	0.2	0.043	0.179
80	0.175	0.036	0.166
100	0.18	0.036	0.171
500	0.379	0.036	0.31
1000	0.604	0.036	0.443

             precision    recall  f1-score   support

          0       0.98      0.89      0.93      4389
          1       0.15      0.48      0.23       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.81+/-0.05, Recall = 0.48+/-0.00

10	0.2	0.04	0.149
20	0.15	0.034	0.136
30	0.2	0.04	0.171
50	0.2	0.04	0.179
80	0.163	0.032	0.157
100	0.17	0.032	0.163
500	0.396	0.033	0.318
1000	0.593	0.033	0.436
10	0.1	0.02	0.085
20	0.15	0.032	0.133
30	0.133	0.027	0.126
50	0.22	0.043	0.191
80	0.163	0.032	0.156
100	0.18	0.034	0.17
500	0.396	0.032	0.318
1000	0.593	0.032	0.435

             precision    recall  f1-score   support

          0       0.98      0.89      0.93      4389
          1       0.15      0.46      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.81+/-0.09, Recall = 0.46+/-0.00

10	0.1	0.01	0.064
20	0.15	0.027	0.119
30	0.167	0.032	0.14
50	0.22	0.045	0.187
80	0.163	0.033	0.154
100	0.18	0.035	0.168
500	0.396	0.035	0.317
1000	0.604	0.035	0.44
10	0.1	0.01	0.064
20	0.2	0.035	0.149
30	0.2	0.037	0.16
50	0.22	0.045	0.186
80	0.163	0.033	0.153
100	0.19	0.037	0.175
500	0.396	0.035	0.316
1000	0.599	0.035	0.436

             precision    recall  f1-score   support

          0       0.98      0.89      0.93      4389
          1       0.14      0.45      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.79+/-0.04, Recall = 0.45+/-0.00

10	0.2	0.031	0.13
20	0.2	0.038	0.155
30	0.233	0.049	0.188
50	0.18	0.036	0.161
80	0.188	0.036	0.171
100	0.24	0.049	0.213
500	0.374	0.035	0.306
1000	0.599	0.035	0.439
10	0.1	0.011	0.066
20	0.2	0.037	0.152
30	0.2	0.04	0.164
50	0.18	0.036	0.16
80	0.188	0.035	0.17
100	0.24	0.049	0.211
500	0.379	0.036	0.308
1000	0.599	0.036	0.438
Counter({0: 426, 1: 426})

             precision    recall  f1-score   support

          0       0.97      0.89      0.93      4389
          1       0.14      0.45      0.22       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.81+/-0.07, Recall = 0.45+/-0.00

10	0.2	0.058	0.173
20	0.2	0.052	0.183
30	0.233	0.058	0.21
50	0.2	0.048	0.192
80	0.188	0.042	0.185
100	0.17	0.038	0.173
500	0.396	0.035	0.323
1000	0.604	0.035	0.446
10	0.2	0.049	0.159
20	0.2	0.046	0.172
30	0.167	0.039	0.157
50	0.2	0.044	0.185
80	0.188	0.039	0.179
100	0.17	0.035	0.168
500	0.396	0.033	0.32
1000	0.61	0.033	0.446

             precision    recall  f1-score   support

          0       0.98      0.88      0.93      4389
          1       0.15      0.49      0.23       182

avg / total       0.94      0.87      0.90      4571

Precision = 0.80+/-0.03, Recall = 0.49+/-0.00

10	0.2	0.037	0.142
20	0.2	0.044	0.165
30	0.2	0.044	0.174
50	0.2	0.044	0.182
80	0.163	0.034	0.159
100	0.17	0.034	0.165
500	0.39	0.033	0.315
1000	0.604	0.033	0.442
10	0.1	0.02	0.085
20	0.2	0.04	0.164
30	0.2	0.043	0.173
50	0.2	0.043	0.181
80	0.175	0.036	0.168
100	0.17	0.035	0.166
500	0.379	0.032	0.308
1000	0.604	0.032	0.442
[ 0.1454328   0.46648352  0.22170792] [ 0.00325611  0.01562798  0.00507504]